{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c36cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distances, LinearAlgebra, Random, Statistics, Distributions, DelimitedFiles\n",
    "include(\"KernelQuantile.jl\")\n",
    "include(\"KernelUtils.jl\")\n",
    "include(\"KernelLogistic.jl\")\n",
    "include(\"KernelMultinomial.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bc0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CSV, DataFrames\n",
    "df = CSV.read(\"codon_usage.csv\", DataFrame)\n",
    "\n",
    "# Replace \"-\" with missing and convert to Float64 for columns 7 and 8\n",
    "for col in [7, 8]\n",
    "    df[!, col] = [x == \"-\" ? missing : (isa(x, AbstractString) ? parse(Float64, x) : x) for x in df[!, col]]\n",
    "end\n",
    "\n",
    "X = Matrix(df[:,7:69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ec535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Impute missing values with column means\n",
    "X_imputed = Matrix{Float64}(undef, size(X))\n",
    "for j in 1:size(X, 2)\n",
    "    col = X[:, j]\n",
    "    non_missing = col[.!ismissing.(col)]\n",
    "    μ = isempty(non_missing) ? 0.0 : mean(non_missing)\n",
    "    X_imputed[:, j] = coalesce.(col, μ)\n",
    "end\n",
    "\n",
    "# 2. Standardize the imputed matrix (center + scale)\n",
    "X_standardized = similar(X_imputed)\n",
    "for j in 1:size(X_imputed, 2)\n",
    "    col = X_imputed[:, j]\n",
    "    μ = mean(col)\n",
    "    σ = std(col)\n",
    "    X_standardized[:, j] = iszero(σ) ? zeros(length(col)) : (col .- μ) ./ σ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "\n",
    "# Step 1: Get unique sorted categories\n",
    "categories = sort(unique(df[:,1]))\n",
    "\n",
    "# Step 2: Create binary matrix\n",
    "Y = zeros(size(df, 1), length(categories))\n",
    "for (i, cat) in enumerate(df[:,1])\n",
    "    col_index = findfirst(isequal(cat), categories)\n",
    "    Y[i, col_index] = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1134e-2790-4e34-9db0-4c1ef50b2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "function nearest_label_classifier(X_train, Y_train, X_test)\n",
    "    labels_train = onehot_to_label(Y_train)\n",
    "    preds = similar(labels_train, size(X_test, 1))\n",
    "\n",
    "    for i in 1:size(X_test, 1)\n",
    "        # Compute squared Euclidean distances to all training points\n",
    "        dists = sum((X_train .- X_test[i, :]') .^ 2, dims=2)\n",
    "        nearest_idx = argmin(dists)\n",
    "        preds[i] = labels_train[nearest_idx]\n",
    "    end\n",
    "\n",
    "    return preds\n",
    "end\n",
    "\n",
    "function onehot_to_label(Y::Matrix)\n",
    "    return findmax.(eachrow(Y)) .|> x -> x[2]\n",
    "end\n",
    "\n",
    "function generate_nystrom_G(n::Int, m::Int, Y::Matrix; rng=Random.GLOBAL_RNG)\n",
    "    # Validate input dimensions\n",
    "    size(Y, 1) == n || error(\"Y must have $n rows\")\n",
    "    \n",
    "    # Convert one-hot matrix to class labels\n",
    "    y = [findfirst(==(1), row) for row in eachrow(Y)]\n",
    "    any(isnothing, y) && error(\"Each row in Y must contain exactly one 1\")\n",
    "    y = convert(Vector{Int}, y)\n",
    "    \n",
    "    # Calculate class distribution and sampling targets\n",
    "    classes = unique(y)\n",
    "    class_counts = [count(==(c), y) for c in classes]\n",
    "    class_proportions = class_counts ./ n\n",
    "    \n",
    "    # Allocate samples per class (maintain proportions)\n",
    "    samples_per_class = zeros(Int, length(classes))\n",
    "    for (i, prop) in enumerate(class_proportions)\n",
    "        samples_per_class[i] = floor(Int, prop * m)\n",
    "    end\n",
    "    \n",
    "    # Distribute remaining samples to largest fractional parts\n",
    "    remainder = m - sum(samples_per_class)\n",
    "    if remainder > 0\n",
    "        fractional_parts = class_proportions .* m .- samples_per_class\n",
    "        top_classes = partialsortperm(fractional_parts, 1:remainder; rev=true)\n",
    "        samples_per_class[top_classes] .+= 1\n",
    "    end\n",
    "\n",
    "    # Perform stratified sampling\n",
    "    selected_indices = Int[]\n",
    "    for (i, c) in enumerate(classes)\n",
    "        class_indices = findall(==(c), y)\n",
    "        n_samples = min(samples_per_class[i], length(class_indices))\n",
    "        append!(selected_indices, sample(rng, class_indices, n_samples; replace=false))\n",
    "    end\n",
    "    \n",
    "    # Final shuffle to avoid class grouping\n",
    "    shuffle!(rng, selected_indices)\n",
    "    \n",
    "    # Construct output matrix efficiently\n",
    "    G = zeros(length(selected_indices), n)\n",
    "    for (i, idx) in enumerate(selected_indices)\n",
    "        G[i, idx] = 1.0\n",
    "    end\n",
    "    return G\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nreps = 20\n",
    "n = size(X,1)*0.8\n",
    "ms = [Int(floor(n/64)),Int(floor(n/32)),Int(floor(n/16)),Int(floor(n/8)),Int(floor(n/4))]\n",
    "times_reduced = zeros(nreps,length(ms))\n",
    "times_full = zeros(nreps,length(ms))\n",
    "times_newton = zeros(nreps,length(ms))\n",
    "times_linear = zeros(nreps)\n",
    "times_nn = zeros(nreps)\n",
    "ll_reduced = zeros(nreps,length(ms))\n",
    "ll_full = zeros(nreps,length(ms))\n",
    "ll_newton = zeros(nreps,length(ms))\n",
    "ll_linear = zeros(nreps)\n",
    "acc_reduced = zeros(nreps,length(ms))\n",
    "acc_full = zeros(nreps,length(ms))\n",
    "acc_newton = zeros(nreps,length(ms))\n",
    "acc_linear = zeros(nreps)\n",
    "acc_nn = zeros(nreps)\n",
    "λs = exp10.(range(1, -5, length=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a59f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:nreps\n",
    "    # Calculate split indices\n",
    "    shuffled_indices = randperm(size(X,1))\n",
    "\n",
    "    train_end = Int(floor(0.7 * size(X,1)))        # 70% training\n",
    "    val_end = train_end + Int(floor(0.1 * size(X,1)))  # 10% validation\n",
    "\n",
    "    # Training set (60%)\n",
    "    train_idx = shuffled_indices[1:train_end]\n",
    "    X_train = X_standardized[train_idx, :]\n",
    "    Y_train = Y[train_idx, :]\n",
    "\n",
    "    # Validation set (20%)\n",
    "    println(train_end)\n",
    "    println(val_end)\n",
    "    val_idx = shuffled_indices[train_end+1:val_end]\n",
    "    \n",
    "    X_val = X_standardized[val_idx, :]\n",
    "    Y_val = Y[val_idx, :]\n",
    "\n",
    "    # Test set (20%)\n",
    "    test_idx = shuffled_indices[val_end+1:end]\n",
    "    X_test = X_standardized[test_idx, :]\n",
    "    Y_test = Y[test_idx, :]\n",
    "\n",
    "    X_train_val = [X_train;X_val]\n",
    "    Y_train_val = [Y_train;Y_val]\n",
    "    \n",
    "    P_pred = zeros(size(Y_test,1),size(Y_test,2))\n",
    "    row_sums_buffer = zeros(size(X_test,1))\n",
    "    time1 = @elapsed B_linear,_,_ = FastMultinomial_reduced([ones(size(X_train,1)) X_train],Y_train, max_iters=5000)\n",
    "    times_linear[i] = time1\n",
    "    compute_probs_reduced!(P_pred,[ones(size(X_test,1)) X_test]*B_linear, row_sums_buffer)\n",
    "    ll_linear[i] = loglikelihood(Y_test, P_pred)\n",
    "    y_true = [argmax(Y_test[i,:]) for i in 1:size(X_test,1)]\n",
    "    y_pred = [argmax(P_pred[i,:]) for i in 1:size(X_test,1)]\n",
    "    acc_linear[i] = mean(y_true .== y_pred)\n",
    "    time2 = @elapsed preds_test = nearest_label_classifier(X_train_val, Y_train_val, X_test)\n",
    "    labels_test = onehot_to_label(Y_test)\n",
    "\n",
    "        # Compute accuracy\n",
    "    acc_nn[i] = mean(preds_test .== labels_test)\n",
    "    println(\"Test accuracy: \", round(acc_nn[i]* 100, digits=2), \"%\")\n",
    "    times_nn[i] = time2\n",
    "    σ = 10.0\n",
    "    K = rbf_kernel(X_train,σ)\n",
    "    n = size(X_train,1)\n",
    "    for j in 1:length(ms)\n",
    "        m = ms[j]\n",
    "        G = generate_nystrom_G(n,m,Y_train)\n",
    "        @time B1s, total_time1 = KernelMultinomial(Y_train,K,G,λs,ϵ=1e-4,verbose=false,tol=1e-2,max_iters=500)\n",
    "        times_reduced[i,j] = total_time1\n",
    "        best_metric = -Inf\n",
    "        best_k = 1\n",
    "        for k in 1:length(λs)\n",
    "            compute_probs_reduced!(P_pred,predict_krr(X_train,X_val,G,B1s[k,:,:],σ), row_sums_buffer)\n",
    "            if loglikelihood(Y_val, P_pred)>best_metric\n",
    "                best_metric = loglikelihood(Y_val, P_pred)\n",
    "                best_k = k\n",
    "            end\n",
    "        end\n",
    "        K1 = rbf_kernel(X_train_val,σ)\n",
    "        G1 = generate_nystrom_G(size(X_train_val,1),m,Y_train_val)\n",
    "        best_B,_,_,_ = KernelMultinomial(Y_train_val,K1,G1,λs[best_k],ϵ=1e-4,verbose=false,tol=1e-2)\n",
    "        compute_probs_reduced!(P_pred,predict_krr(X_train_val,X_test,G1,best_B,σ), row_sums_buffer)\n",
    "        ll_reduced[i,j] = loglikelihood(Y_test, P_pred)\n",
    "        y_true = [argmax(Y_test[i,:]) for i in 1:size(X_test,1)]\n",
    "        y_pred = [argmax(P_pred[i,:]) for i in 1:size(X_test,1)]\n",
    "        acc_reduced[i,j] = mean(y_true .== y_pred)\n",
    "        @time B2s, total_time2 = KernelMultinomial_full(Y_train,K,G,λs,ϵ=1e-4,verbose=false,tol=1e-2,max_iters=500)\n",
    "        times_full[i,j] = total_time2\n",
    "        best_metric = -Inf\n",
    "        best_k = 1\n",
    "        for k in 1:length(λs)\n",
    "            compute_probs!(P_pred,predict_krr(X_train,X_val,G,B2s[k,:,:],σ), row_sums_buffer)\n",
    "            if loglikelihood(Y_val, P_pred)>best_metric\n",
    "                best_metric = loglikelihood(Y_val, P_pred)\n",
    "                best_k = k\n",
    "            end\n",
    "        end\n",
    "        best_B,_,_,_ = KernelMultinomial_full(Y_train_val,K1,G1,λs[best_k],ϵ=1e-4,verbose=false,tol=1e-2)\n",
    "        compute_probs!(P_pred,predict_krr(X_train_val,X_test,G1,best_B,σ), row_sums_buffer)\n",
    "        ll_full[i,j] = loglikelihood(Y_test, P_pred)\n",
    "        y_true = [argmax(Y_test[i,:]) for i in 1:size(X_test,1)]\n",
    "        y_pred = [argmax(P_pred[i,:]) for i in 1:size(X_test,1)]\n",
    "        acc_full[i,j] = mean(y_true .== y_pred)\n",
    "        if m>1000\n",
    "            continue\n",
    "        else\n",
    "            @time B3s, total_time3 = KernelMultinomial_newton(Y_train,K,G,λs,ϵ=1e-4,verbose=false,tol=1e-2)\n",
    "            times_newton[i,j] = total_time3\n",
    "            best_metric = -Inf\n",
    "            best_k = 1\n",
    "            for k in 1:length(λs)\n",
    "                compute_probs_reduced!(P_pred,predict_krr(X_train,X_val,G,B3s[k,:,:],σ), row_sums_buffer)\n",
    "                if loglikelihood(Y_val, P_pred)>best_metric\n",
    "                    best_metric = loglikelihood(Y_val, P_pred)\n",
    "                    best_k = k\n",
    "                end\n",
    "            end\n",
    "            best_B,_,_,_ = KernelMultinomial_newton(Y_train_val,K1,G1,λs[best_k],ϵ=1e-4,verbose=false,tol=1e-2)\n",
    "            compute_probs_reduced!(P_pred,predict_krr(X_train_val,X_test,G1,best_B,σ), row_sums_buffer)\n",
    "            ll_newton[i,j] = loglikelihood(Y_test, P_pred)\n",
    "            y_true = [argmax(Y_test[i,:]) for i in 1:size(X_test,1)]\n",
    "            y_pred = [argmax(P_pred[i,:]) for i in 1:size(X_test,1)]\n",
    "            acc_newton[i,j] = mean(y_true .== y_pred)\n",
    "        end\n",
    "        writedlm(\"times_reduced.csv\",times_reduced,\",\")\n",
    "        writedlm(\"times_full.csv\",times_full,\",\")\n",
    "        writedlm(\"times_newton.csv\",times_newton,\",\")\n",
    "        writedlm(\"times_linear.csv\",times_linear,\",\")\n",
    "        writedlm(\"times_nn.csv\",times_nn,\",\")\n",
    "        writedlm(\"ll_reduced.csv\",ll_reduced,\",\")\n",
    "        writedlm(\"ll_full.csv\",ll_full,\",\")\n",
    "        writedlm(\"ll_newton.csv\",ll_newton,\",\")\n",
    "        writedlm(\"ll_linear.csv\",ll_linear,\",\")\n",
    "        writedlm(\"acc_reduced.csv\",acc_reduced,\",\")\n",
    "        writedlm(\"acc_full.csv\",acc_full,\",\")\n",
    "        writedlm(\"acc_newton.csv\",acc_newton,\",\")\n",
    "        writedlm(\"acc_linear.csv\",acc_linear,\",\")\n",
    "        writedlm(\"acc_nn.csv\",acc_nn,\",\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746e81f-cbe7-43bc-a1a9-b4db51474a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(times_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb76da3-6ca3-4452-80ef-aaa648e36605",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(times_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018b0d2-34d2-4f6e-816e-1a9da8e6299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(times_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b56f8-92fa-48fb-ad1f-08dcebdeb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(times_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec3160-8a13-4274-b2a1-9d1e055b81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(times_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05309700-e60f-4d89-bb07-5bb5cea8087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(times_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04ec0c-8684-4b12-8238-7e9612b012d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(ll_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669cdd8-e822-4cd3-a9ca-08594a4ad5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(ll_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ac8e2-9868-41e8-bd46-3890e4169ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(ll_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec027fca-159a-4ca5-bdae-723a44d15439",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(ll_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f43c1-0865-4250-a471-b1c3a5923613",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(ll_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7f0fd-863e-40c2-9837-f5304eba7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(ll_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5769f9d-6b63-4b94-961c-321201af7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(acc_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b8466-853b-4d47-b247-c14bebe84bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(acc_reduced,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca95f58-9828-4b91-a734-41a42afd4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(acc_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08297e8c-6d27-4959-9a16-c73c321c3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(acc_full,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3193c1-8521-4aa5-9163-da1a927275f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(acc_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f0d80-c25e-4c2e-ae26-f868732b35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(acc_newton,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d8939-fc70-433c-83a3-7ea1c9b50ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(acc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8de1e-4213-40bf-b966-b5539e9f4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(acc_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
